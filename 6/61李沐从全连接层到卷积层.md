# 不变性

假设你想从一张图片中找到某个物体。 合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。 

沃尔多的样子并不取决于他潜藏的地方，因此我们可以使用一个“沃尔多检测器”扫描图像。 

该检测器将图像分割成多个区域，并==为每个区域包含沃尔多的可能性打分==。 

卷积神经网络正是将==*空间不变性*（spatial invariance）==的这一概念系统化，从而基于这个模型==使用较少的参数==来学习有用的表示。

### 总结

1. *平移不变性*（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的==前面几层==应该对==相同的图像区域==具有==相似的反应==，即为“平移不变性”。
2. *局部性*（locality）：神经网络的==前面几层==应该==只探索==输入图像中的==局部区域==，而==不过度在意==图像中相隔==较远区域==的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。

让我们看看这些原则是如何转化为数学表示的。

# 多层感知机限制

![image-20220708211948275](D:\论文\截图\image-20220708211948275.png)

这里讲的是==MLP放到图片上4维是怎么一个思路，由此用平移不变性和局部性来推导卷积层==



故证明后，==卷积层就是一个特殊的MLP==

![image-20220708214355941](D:\论文\截图\image-20220708214355941.png)

在全连接层中，输入我们把宽高和那个地点的值（本来是一个矩阵）拉成了一个向量。

现在我们还是作为一个矩阵。（MLP中是向量）

此时，我们的==权重==则变为一个四维的张量（本来是一个跟输入同维度的向量w，好几个w分别w1、w2构成一个矩阵来产生多维的输出而不是一个输出）



那么，==因为输入和输出都是矩阵，则w是四维==，

原来是1+1维，现在说2+2维

原来是输入到输出，现在是输入的高宽对应值   到   输出高宽对应值



$h_{i,j}$ 就是输出的i，j点上的值

$x_{k,l}$ 就是输入的k，l点上的值

w就由原来的2维变到4维。

原来就是w1对应的h1这个输出的神经元，然后w1是一个向量与x所有值一一对应，即按位置乘起来加和得到h1，多个h1、h2合并成h这个输出的向量。

==现在就是$h_{i,j}$上的每个点唯一对应一个$w_{i,j}$ ,这个$w_{i,j}$与x的所有值相乘并加和，这个相乘加和的过程就是以（k，l）作为迭代==





此时，==对w做一个重新索引，也就是对w重新排列一下==

![image-20220708220737186](D:\论文\截图\image-20220708220737186.png)

即

![image-20220708222544943](D:\论文\截图\image-20220708222544943.png)

此时，也要对x做些变化（不是改变x的值，而是在一一对应的迭代时，改一下下标的索引方法，使得用ab来一一对应）

即$k=i+a，l=j+b$

==以此更改x的下标==和w的下标，然后用ab来迭代，==这里的ab是可以为负数的==

即

# $\sum_{a,b}w_{i,j,i+a,j+b}x_{i+a,j+b}$



然后把w做一个变化成为v

==w的$i+a，j+b$ 变为v的a和b==

则变为上式

（此时的v有点不太对，因为ab可负，即不能直观的想象，而是知道ab为负数的时候，也是一个索引，ab的索引跟i j一起组成一个唯一的值，多个唯一的值组成了四维的V，这个唯一的值表示了x矩阵到h矩阵的一个映射的==加和的一个分量==，这个分量以ab为迭代加起来形成==h中i j点的输出值==）







# ==(简单来说，w和v中包含的所有的值是一样的，但是索引不一样了，$w是{i,j,i+a,j+b},v是i，j,a,b$)==

==其中ab可负==







==此处还是全连接层，只不过写成二维矩阵的计算形式并且把下标做个变换==



（$为什么要在x中加上i和j呢，因为下面要引出在x（即输入图像中）平移，那么也导致在输出h中的结果平移。所以i和j在x和h中对应$）





### 平移不变性

![image-20220708212717946](D:\论文\截图\image-20220708212717946.png)

![image-20220708224139792](D:\论文\截图\image-20220708224139792.png)

x中平移导致输出的结果在h中平移。这个的坐标是$i，j$

==所以权重v不应该依赖于$i，j$==

所以

![image-20220708225012719](D:\论文\截图\image-20220708225012719.png)

==$即不管i，j怎么变，v应该是不变的$==



我们在此对其加一个限制，这样满足了==全连接到卷积的第一步==



严格在数学上叫交叉相关

通俗上叫2维卷积



（卷积原本也就是一个不变的函数乘以一个变动的函数）（此时v也就从变动变为不变）



当我们把模型的取值范围做了限制（取消了ij），那么我们模型的复杂度也就降低了



### 局部性

![image-20220708212730661](D:\论文\截图\image-20220708212730661.png)

==（这个概念不用看，直接看下面对于视频截图的讲解）==（简而言之， 6.1.3式是一个*卷积层*（convolutional layer），而卷积神经网络是包含卷积层的一类特殊的神经网络。

 在深度学习研究社区中，V被称为*卷积核*（convolution kernel）或者*滤波器*（filter），亦或简单地称之为该卷积层的*权重*，通常该权重是可学习的参数。 当图像处理的局部区域很小时，卷积神经网络与多层感知机的训练差异可能是巨大的：以前，多层感知机可能需要数十亿个参数来表示网络中的一层，而现在卷积神经网络通常只需要几百个参数，而且不需要改变输入或隐藏表示的维数。 参数大幅减少的代价是，我们的特征现在是平移不变的，并且当确定每个隐藏活性值时，每一层只包含局部的信息。 以上所有的权重学习都将依赖于归纳偏置。当这种偏置与现实相符时，我们就能得到样本有效的模型，并且这些模型能很好地泛化到未知数据中。 但如果这偏置与现实不符时，比如当图像不满足平移不变时，我们的模型可能难以拟合我们的训练数据。）

![image-20220708230011777](D:\论文\截图\image-20220708230011777.png)

我们对于全连接，我们计算的其实就是一整个图片，所以ab可以从很小迭代到很大来计算==整张图片的其他位置对于我们这个像素点 i，j的影响==

但是对于图像识别中，==我们应在意局部，而不是过远的点==

所以

![image-20220708230357473](D:\论文\截图\image-20220708230357473.png)

==也就是只对ab在正负$\delta$ 内的时候的乘积做累加==





![image-20220708230755386](D:\论文\截图\image-20220708230755386.png)

也就是==卷积神经网络中卷积操作取目标点附近一块做对应位置乘积加和赋值到输出的对应点==



### 总结

卷积是一个特殊的全连接层

![image-20220708230929800](D:\论文\截图\image-20220708230929800.png)









==（下面的不是很重要）==

# 卷积

![image-20220708213043412](D:\论文\截图\image-20220708213043412.png)

卷积这个是因为类似于一个数学概念所以那么叫，具体这个数学概念可以回看王木头视频



# 通道

![image-20220708213137403](D:\论文\截图\image-20220708213137403.png)

其中隐藏表示H中的索引d表示输出通道，而随后的输出将继续以三维张量H作为输入进入下一个卷积层。

所以，6.1.7式可以定义具有多个通道的卷积层，而其中V是该卷积层的权重。

然而，仍有许多问题亟待解决。 例如，图像中是否到处都有存在沃尔多的可能？如何有效地计算输出层？如何选择适当的激活函数？为了训练有效的网络，如何做出合理的网络设计选择？我们将在本章的其它部分讨论这些问题。