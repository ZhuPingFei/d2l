# 具体细节可以看论文精读那里

2001年主流：用核函数来计算相关性

如何判断两个点在高维线性相关

线性就直接做内积。核方法就是扭曲空间，把空间拉成我们想要的样子。



通过核函数计算以后，问题就会变成一个凸优化问题

![image-20220828142915016](D:\论文\截图\image-20220828142915016.png)

==原先不在意分类模型——如：svm还是感知机模型==

==而在意特征提取==

整个计算机视觉，针对不同类别进行不同的特征提取







发展趋势

![image-20220828143141292](D:\论文\截图\image-20220828143141292.png)

![image-20220828143542779](D:\论文\截图\image-20220828143542779.png)

计算涨的比数据快



一开始都适中，可以选择小模型神经网络

后来因为核方法可以解释并且能跑

再后来计算涨的快，可以构建更深的神经网络





# AlexNet

![image-20220828193238102](D:\论文\截图\image-20220828193238102.png)

![image-20220828144151346](D:\论文\截图\image-20220828144151346.png)

丢弃法见46

==原因：模型更大了，所以用丢弃法来做一些正则==

==ReLu比起sigmoid，梯度更大、在零点处一阶导更加接近y=x，能够支持更深的模型==

==maxpooling输出的值比较大，梯度比较大，得到需要的值更加容易一点==



AlexNet相比LeNet不止更大更深

LeNet本质还是一个机器学习的模型，AlexNet增大了几十倍，量变引起了质变。



把计算机视觉的观念改变了(图片右边)



==原先==是对一张图片，做人工的特征提取，计算机视觉研究者主要关心你是怎么做的这个特征提取，接下来用一个标准的机器学习模型如SVM。即把研究重心放在如何把抽象的数据转化为机器学习可以处理的数值。

![image-20220828150436942](D:\论文\截图\image-20220828150436942.png)

==而深度学习神经网络==，最后只有一个softmax回归来进行分类，之前的所有层都可以看做使用CNN卷积神经网络来对特征进行学习。

并且同时使得原本割裂的特征提取和分类算法变成了一个整体的网络，CNN和softmax这是放在一起训练的，更加高效和好用。

![image-20220828150423667](D:\论文\截图\image-20220828150423667.png)

# AlexNet架构

![image-20220828150850865](D:\论文\截图\image-20220828150850865.png)

右边下面是32X32



1、AlexNet用了一个==更大的核窗口==，11X11

图片变大了，一次需要更多的信息，用11X11

同时，步长也变成了4，更大了。（当时GPU没那么好用，stride少了内存不够跑）

2、==更多的输出通道数==，从6变成了96，这样可以在第一层就识别更多的图片的模式

3、更大的池化层并且是maxpooling

注意，LeNet2X2步长为2，每次看的窗口不重叠。

所以==允许一个像素  往一边   移动一点的误差==，因为2X2相当于每次包含周围一个像素，此时这个移动对于2X2池化不影响其输出

==而AlexNet用3X3而步长还是2==，所以==允许一个像素往   左右都可以  移动一点的误差==



池化层stride等于2就是把输出的变成输入的高宽减半



后面

![image-20220828153252534](D:\论文\截图\image-20220828153252534.png)

LeNet在后面又接了一个5X5的卷积层，通道数16，然后是一个2X2的均值池化



AlexNet也是5X5卷积并且pad2

pad2是为了让5X5的卷积层的输入输出一样大

1、==用了256个输出通道，可以识别更多的模式==

2、新加了三个卷积层，pad1是让3X3的卷积输入输出长一样

以及384个输出通道





==然后把池化完的各个输出通道展平成一个   数组   用来全连接==

最后的多个全连接层

![image-20220828154658859](D:\论文\截图\image-20220828154658859.png)

LeNet先从池化完的==16（通道）X5X5（池化完缩放出来的不同通道的矩阵）==    ==展平==   ==成400的数组==

然后全连接变到120、再到84、再到10 

10类，即数字



AlexNet也类似，展平

然后全连接变到4096、再到4096、再到1000

1000类

（注：下层网络比上层网络一般要大，最后要1000，下层得大于1000）

![image-20220828155938768](D:\论文\截图\image-20220828155938768.png)

丢弃层在两个4096全连接层之后。dropout是用于全连接层来对模型进行正则化的



数据增强：

![image-20220828160117027](D:\论文\截图\image-20220828160117027.png)

假设原始图片是猫

假设这次我要读他进去（随机梯度下降，故本次不一定读入这张图片）

不会直接放进这张图片

而是随机截取、随机调高调低亮度色温等等。



因为卷积对于光线、颜色等等很敏感，那么要使得模型不敏感，则在放进图片过程中随机对图片进行这类操作

==之后会有课专门来讲这种数据增强的方法==







![image-20220828160548553](D:\论文\截图\image-20220828160548553.png)

左边是空间复杂度，==存的参数==

右边是时间复杂度，即==计算浮点数的次数==



increase就是数量级的对比，空间复杂度约大十倍，时间复杂度约大250倍







![image-20220828161129271](D:\论文\截图\image-20220828161129271.png)